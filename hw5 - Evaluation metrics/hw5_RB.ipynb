{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 5: Evaluation metrics\n",
    "### Associated lectures: [Lectures 9, 10](https://ubc-cs.github.io/cpsc330/README.html) \n",
    "\n",
    "**Due date: Monday, Feb 27, 2023 at 11:59pm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "from hashlib import sha1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import tests_hw5 # note: commented out as discussed here https://piazza.com/class/lcgo6c2ncl06el/post/419\n",
    "from sklearn import datasets\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier, DummyRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions \n",
    "<hr>\n",
    "rubric={points:3}\n",
    "\n",
    "Follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330-2022W2/blob/main/docs/homework_instructions.md). \n",
    "\n",
    "**You may work with a partner on this homework and submit your assignment as a group.** Below are some instructions on working as a group.  \n",
    "- The maximum group size is 2. \n",
    "- Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "- Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "- It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "- You can find the instructions on how to do group submission on Gradescope [here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Precision, recall, and f1 score by hand <a name=\"1\"></a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the problem of predicting whether a patient has cancer or not. It is important to catch this disease early to reduce mortality rate; late diagnosis will result in metastasis to other organs, which adversely impacts patient's prognosis. Below are confusion matrices of two machine learning models: Model A and Model B. \n",
    "\n",
    "- Model A\n",
    "\n",
    "|         | Predicted disease | Predicted no disease |\n",
    "| :------------- | -----------------------: | -----------------------: |\n",
    "| **Actual disease**       | 48 | 32 |\n",
    "| **Actual no disease**       | 20 | 100 |\n",
    "\n",
    "\n",
    "- Model B\n",
    "\n",
    "|        | Predicted disease | Predicted no disease |\n",
    "| :------------- | -----------------------: | -----------------------: |\n",
    "| **Actual disease**       | 43 | 22 |\n",
    "| **Actual no disease**       | 35 | 100 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Positive vs. negative class \n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Precision, recall, and f1 score depend upon which class is considered \"positive\", that is the thing you wish to find. In the example above, which class is likely to be the \"positive\" class? Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The positive class is likely to be the 'disease' class, with the 'predicted disease' being the predicted positive class (and the 'actual disease' being the actual positive class). This is because our task is to identify those with the disease, rather than those without the disease. The 'disease' class being smaller or rarer than the 'no disease' class also supports this, as we are usually trying to identify the rarer class and it is therefore labelled 'positive'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Accuracy\n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Calculate accuracies for Model A and Model B. \n",
    "\n",
    "We'll store all metrics associated with Model A and Model B in the `results_dict` below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {\"A\": {}, \"B\": {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict[\"A\"][\"accuracy\"] = None\n",
    "results_dict[\"B\"][\"accuracy\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model A accuracy: 0.74\n",
      "Model B accuracy: 0.715\n"
     ]
    }
   ],
   "source": [
    "modelA_accuracy = (48+100)/(48+100+20+32)\n",
    "modelB_accuracy = (43+100)/(43+100+35+22)\n",
    "results_dict[\"A\"][\"accuracy\"] = modelA_accuracy\n",
    "results_dict[\"B\"][\"accuracy\"] = modelB_accuracy\n",
    "print(\"Model A accuracy:\", results_dict[\"A\"][\"accuracy\"])\n",
    "print(\"Model B accuracy:\", results_dict[\"B\"][\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Which model would you pick? \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Which model would you pick simply based on the accuracy metric? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply by the accuracy metric, model A performed better than model B, so I would choose model A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Precision, recall, f1-score\n",
    "rubric={points:6}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Calculate precision, recall, f1-score for Model A and Model B manually, without using `scikit-learn` tools. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict[\"A\"][\"precision\"] = None\n",
    "results_dict[\"B\"][\"precision\"] = None\n",
    "results_dict[\"A\"][\"recall\"] = None\n",
    "results_dict[\"B\"][\"recall\"] = None\n",
    "results_dict[\"A\"][\"f1\"] = None\n",
    "results_dict[\"B\"][\"f1\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision = (TP/TP+FP)\n",
    "modelA_precision = 48/(48+20)\n",
    "modelB_precision = 43/(43+35)\n",
    "#recall = (TP/TP+FN)\n",
    "modelA_recall = 48/(48+32)\n",
    "modelB_recall = 43/(43+22)\n",
    "#f1 = 2*(prec*rec/prec+rec)\n",
    "modelA_f1 = 2*((modelA_precision*modelA_recall)/(modelA_precision+modelA_recall))\n",
    "modelB_f1 = 2*((modelB_precision*modelB_recall)/(modelB_precision+modelB_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict[\"A\"][\"precision\"] = modelA_precision\n",
    "results_dict[\"B\"][\"precision\"] = modelB_precision\n",
    "results_dict[\"A\"][\"recall\"] = modelA_recall\n",
    "results_dict[\"B\"][\"recall\"] = modelB_recall\n",
    "results_dict[\"A\"][\"f1\"] = modelA_f1\n",
    "results_dict[\"B\"][\"f1\"] = modelB_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the dataframe with all results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.715000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.551282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.661538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.601399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  A         B\n",
       "accuracy   0.740000  0.715000\n",
       "precision  0.705882  0.551282\n",
       "recall     0.600000  0.661538\n",
       "f1         0.648649  0.601399"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Discussion\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Given the type of problem (early cancer diagnosis), which metric is more informative in this problem? Why? \n",
    "2. Which model would you pick based on this information? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers:\n",
    "1. Recall is more important than precision, because we want to catch as many of the cancer cases as we can, and false positives do not matter as much in this case. Someone with cancer being undiagnosed (a false negative) could lead to the disease getting worse and therefore would be less desireable than someone being told they have cancer when they do not (a fase positive). As recall accounts for false negatives, whereas precision focuses on fase positives, recall is more informative for this problem.\n",
    "2. Based on this information, I would pick model B. Though it has lower accuracy, precision and f1 scores than model A, it has a significantly higher recall, which makes it more appropriate for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 1.6 \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Provide 2 to 3 example classification datasets (with links) where accuracy metric would be misleading. Discuss which evaluation metric would be more appropriate for each dataset. You may consider datasets we have used in this course so far. You could also look up datasets on Kaggle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples:\n",
    "* Heart Attack Analysis & Prediction Dataset https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset \n",
    "    \n",
    "    Recall would be appropriate for this dataset, which has a target feature that classifies samples by whether they are likely to have a heart attack or not. If the   dataset was to be used to train a model that would identify which patients were likely to have a heart attack, false positives would usually not be as important as false negatives (as the patient may die if not identified). Therefore recall would be more important than f1, precision, or accuracy.\n",
    "\n",
    "* Spam Email Data original & CSV file (Spamassassin) https://www.kaggle.com/datasets/cesaber/spam-email-data-spamassassin-2002\n",
    "    \n",
    "    False negatives (saying an email is not spam when it is) could be very bad here, as it would lead the spam to end up in the inbox and could lead to annoyance or even danger of e.g. getting a virus. However, false positives could possibly be even worse, as a very strict spam filter may cause real (ham) emails to not appear in the inbox, which would be a big incovenience for the user. A model with a high number of false positives but very low number of false negatives may have a high accuracy, but this would be misleading about the usability of the model. In this case, f1 score may be more informative, as it considers bot precision and recall without assuming that false negatives and false positives have an equal cost (as accuracy does)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Classification evaluation metrics using `sklearn` <a name=\"2\"></a>\n",
    "<hr>\n",
    "\n",
    "In general, when a dataset is imbalanced, accuracy does not provide the whole story. In class, we looked at credit card fraud dataset which is a classic example of an imbalanced dataset. \n",
    "\n",
    "Another example is customer churn datasets. [Customer churn](https://en.wikipedia.org/wiki/Customer_attrition) refers to the notion of customers leaving a subscription service like Netflix. In this exercise, we will try to predict customer churn in a dataset where most of the customers stay with the service and a small minority cancel their subscription. To start, please download the [Kaggle telecom customer churn dataset](https://www.kaggle.com/becksddf/churn-in-telecoms-dataset). Once you have the data, you should be able to run the following code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The starter code below reads the data CSV as a pandas dataframe and splits it into 70% train and 30% test. \n",
    "\n",
    "Note that `churn` column in the dataset is the target. \"True\" means the customer left the subscription (churned) and \"False\" means they stayed.\n",
    "\n",
    "> Note that for this kind of problem a more appropriate technique is something called survival analysis and we'll be talking about it later in the course. For now, we'll just treat it as a binary classification problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>phone number</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>...</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>NE</td>\n",
       "      <td>70</td>\n",
       "      <td>415</td>\n",
       "      <td>421-8535</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>213.4</td>\n",
       "      <td>86</td>\n",
       "      <td>36.28</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>17.40</td>\n",
       "      <td>256.6</td>\n",
       "      <td>101</td>\n",
       "      <td>11.55</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>WI</td>\n",
       "      <td>67</td>\n",
       "      <td>510</td>\n",
       "      <td>417-2265</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>109.1</td>\n",
       "      <td>134</td>\n",
       "      <td>18.55</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>12.10</td>\n",
       "      <td>91.2</td>\n",
       "      <td>86</td>\n",
       "      <td>4.10</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>NJ</td>\n",
       "      <td>122</td>\n",
       "      <td>415</td>\n",
       "      <td>327-9341</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>34</td>\n",
       "      <td>146.4</td>\n",
       "      <td>104</td>\n",
       "      <td>24.89</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>7.62</td>\n",
       "      <td>220.0</td>\n",
       "      <td>91</td>\n",
       "      <td>9.90</td>\n",
       "      <td>15.6</td>\n",
       "      <td>4</td>\n",
       "      <td>4.21</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>NV</td>\n",
       "      <td>107</td>\n",
       "      <td>510</td>\n",
       "      <td>419-9688</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>234.1</td>\n",
       "      <td>91</td>\n",
       "      <td>39.80</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>13.86</td>\n",
       "      <td>282.5</td>\n",
       "      <td>100</td>\n",
       "      <td>12.71</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2638</th>\n",
       "      <td>HI</td>\n",
       "      <td>105</td>\n",
       "      <td>510</td>\n",
       "      <td>364-8128</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>125.4</td>\n",
       "      <td>116</td>\n",
       "      <td>21.32</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>22.23</td>\n",
       "      <td>241.6</td>\n",
       "      <td>104</td>\n",
       "      <td>10.87</td>\n",
       "      <td>11.4</td>\n",
       "      <td>9</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>WY</td>\n",
       "      <td>126</td>\n",
       "      <td>408</td>\n",
       "      <td>339-9798</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>197.6</td>\n",
       "      <td>126</td>\n",
       "      <td>33.59</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>20.95</td>\n",
       "      <td>285.3</td>\n",
       "      <td>104</td>\n",
       "      <td>12.84</td>\n",
       "      <td>12.5</td>\n",
       "      <td>8</td>\n",
       "      <td>3.38</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>WV</td>\n",
       "      <td>70</td>\n",
       "      <td>510</td>\n",
       "      <td>348-3777</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>30</td>\n",
       "      <td>143.4</td>\n",
       "      <td>72</td>\n",
       "      <td>24.38</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>14.45</td>\n",
       "      <td>127.9</td>\n",
       "      <td>68</td>\n",
       "      <td>5.76</td>\n",
       "      <td>9.4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.54</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>NJ</td>\n",
       "      <td>125</td>\n",
       "      <td>415</td>\n",
       "      <td>406-6400</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>182.3</td>\n",
       "      <td>64</td>\n",
       "      <td>30.99</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>11.88</td>\n",
       "      <td>171.6</td>\n",
       "      <td>96</td>\n",
       "      <td>7.72</td>\n",
       "      <td>11.6</td>\n",
       "      <td>7</td>\n",
       "      <td>3.13</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>NE</td>\n",
       "      <td>159</td>\n",
       "      <td>415</td>\n",
       "      <td>362-5111</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>189.1</td>\n",
       "      <td>105</td>\n",
       "      <td>32.15</td>\n",
       "      <td>...</td>\n",
       "      <td>147</td>\n",
       "      <td>20.92</td>\n",
       "      <td>242.0</td>\n",
       "      <td>106</td>\n",
       "      <td>10.89</td>\n",
       "      <td>10.4</td>\n",
       "      <td>5</td>\n",
       "      <td>2.81</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>PA</td>\n",
       "      <td>106</td>\n",
       "      <td>408</td>\n",
       "      <td>403-9167</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>133.7</td>\n",
       "      <td>45</td>\n",
       "      <td>22.73</td>\n",
       "      <td>...</td>\n",
       "      <td>107</td>\n",
       "      <td>15.96</td>\n",
       "      <td>181.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.19</td>\n",
       "      <td>10.7</td>\n",
       "      <td>2</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2333 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  account length  area code phone number international plan  \\\n",
       "1402    NE              70        415     421-8535                 no   \n",
       "1855    WI              67        510     417-2265                 no   \n",
       "633     NJ             122        415     327-9341                 no   \n",
       "1483    NV             107        510     419-9688                yes   \n",
       "2638    HI             105        510     364-8128                 no   \n",
       "...    ...             ...        ...          ...                ...   \n",
       "2154    WY             126        408     339-9798                yes   \n",
       "3089    WV              70        510     348-3777                 no   \n",
       "1766    NJ             125        415     406-6400                 no   \n",
       "1122    NE             159        415     362-5111                 no   \n",
       "1346    PA             106        408     403-9167                yes   \n",
       "\n",
       "     voice mail plan  number vmail messages  total day minutes  \\\n",
       "1402              no                      0              213.4   \n",
       "1855              no                      0              109.1   \n",
       "633              yes                     34              146.4   \n",
       "1483              no                      0              234.1   \n",
       "2638              no                      0              125.4   \n",
       "...              ...                    ...                ...   \n",
       "2154              no                      0              197.6   \n",
       "3089             yes                     30              143.4   \n",
       "1766              no                      0              182.3   \n",
       "1122              no                      0              189.1   \n",
       "1346              no                      0              133.7   \n",
       "\n",
       "      total day calls  total day charge  ...  total eve calls  \\\n",
       "1402               86             36.28  ...               77   \n",
       "1855              134             18.55  ...               76   \n",
       "633               104             24.89  ...              103   \n",
       "1483               91             39.80  ...              105   \n",
       "2638              116             21.32  ...               95   \n",
       "...               ...               ...  ...              ...   \n",
       "2154              126             33.59  ...              112   \n",
       "3089               72             24.38  ...               92   \n",
       "1766               64             30.99  ...              121   \n",
       "1122              105             32.15  ...              147   \n",
       "1346               45             22.73  ...              107   \n",
       "\n",
       "      total eve charge  total night minutes  total night calls  \\\n",
       "1402             17.40                256.6                101   \n",
       "1855             12.10                 91.2                 86   \n",
       "633               7.62                220.0                 91   \n",
       "1483             13.86                282.5                100   \n",
       "2638             22.23                241.6                104   \n",
       "...                ...                  ...                ...   \n",
       "2154             20.95                285.3                104   \n",
       "3089             14.45                127.9                 68   \n",
       "1766             11.88                171.6                 96   \n",
       "1122             20.92                242.0                106   \n",
       "1346             15.96                181.9                 89   \n",
       "\n",
       "      total night charge  total intl minutes  total intl calls  \\\n",
       "1402               11.55                 5.7                 4   \n",
       "1855                4.10                10.9                 5   \n",
       "633                 9.90                15.6                 4   \n",
       "1483               12.71                10.0                 3   \n",
       "2638               10.87                11.4                 9   \n",
       "...                  ...                 ...               ...   \n",
       "2154               12.84                12.5                 8   \n",
       "3089                5.76                 9.4                 4   \n",
       "1766                7.72                11.6                 7   \n",
       "1122               10.89                10.4                 5   \n",
       "1346                8.19                10.7                 2   \n",
       "\n",
       "      total intl charge  customer service calls  churn  \n",
       "1402               1.54                       1  False  \n",
       "1855               2.94                       2  False  \n",
       "633                4.21                       2  False  \n",
       "1483               2.70                       1  False  \n",
       "2638               3.08                       2  False  \n",
       "...                 ...                     ...    ...  \n",
       "2154               3.38                       2  False  \n",
       "3089               2.54                       3  False  \n",
       "1766               3.13                       2  False  \n",
       "1122               2.81                       1   True  \n",
       "1346               2.89                       1   True  \n",
       "\n",
       "[2333 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"bigml_59c28831336c6604c800002a.csv\", encoding=\"utf-8\")\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=123)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Distribution of target values\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Examine the distribution of target values in the train split. Do you see class imbalance? If yes, do we need to deal with it? Why or why not? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1984\n",
       "True      349\n",
       "Name: churn, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"churn\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is class imbalance, as the number of samples with churn=True are much lower than ones with churn=False.\n",
    "\n",
    "This is likely due to the churn=True class being more rare than churn=False, as most customers don't unsubscribe. Therefore, we may want to do something about the imbalance if we care more about one type of error over another. In this case, we may care more about identifying the customers that unsubscribed (churn=True) than those who didn't (churn=False). Then, false positives matter less than false negatives, as a false negative means we missed someone who would unsubscribe. Therefore recall would be more important than precision, as it accounts for false positives. We could deal with this by reweighting the classes or using other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 2.2 EDA \n",
    "rubric={points:1}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Come up with **two** exploratory questions you would like to answer and explore those. Briefly discuss your results in 1-3 sentences.\n",
    "\n",
    "You are welcome to use `pandas_profiling` (see Lecture 10) but you don't have to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99fd086bb61f4ae6955718384355e7f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olsen L\\.conda\\envs\\cpsc330\\lib\\site-packages\\multimethod\\__init__.py:184: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  return self[tuple(map(self.get_type, args))](*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d9f2a462c24a4ab1f3edc0767945ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c66cd89e4e3d469a8bc677276eea78b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942b2899d1554e4c85bade1858c32e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#code based on lecture 10\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "profile = ProfileReport(train_df, title=\"Pandas Profiling Report\")  # , minimal=True)\n",
    "profile. to_file(\"HW5 Report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "1. What is the relationship between voice mail plan and vmail messages? If they are measuring similar things it may be uneccessary to include them both in the model.\n",
    "2. Which variables have the strongest covariance with churn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Column transformer \n",
    "rubric={points:14}\n",
    "\n",
    "The code below creates `X_train`, `y_train`, `X_test`, `y_test` for you. \n",
    "In preparation for building a classifier, set up a `ColumnTransformer` that performs whatever feature transformations you deem sensible. This can include dropping features if you think they are not helpful. Remember that by default `ColumnTransformer` will drop any columns that aren't accounted for when it's created.\n",
    "\n",
    "For each group of features (e.g. numeric, categorical or else) explain why you are applying the particular transformation. For example, \"I am doing transformation X to the following categorical features: `a`, `b`, `c` because of reason Y,\" etc.\n",
    "\n",
    "Finally, fit `ColumnTransformer` on your training set; and use the `ColumnTransformer` to transform your train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=[\"churn\"])\n",
    "X_test = test_df.drop(columns=[\"churn\"])\n",
    "\n",
    "y_train = train_df[\"churn\"]\n",
    "y_test = test_df[\"churn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code based on lecture 6\n",
    "numeric_features = [\n",
    "    \"account length\",\n",
    "    \"number vmail messages\",\n",
    "    \"total day minutes\",\n",
    "    \"total day calls\",\n",
    "    \"total day charge\",\n",
    "    \"total eve minutes\",\n",
    "    \"total eve calls\",\n",
    "    \"total eve charge\",\n",
    "    \"total night minutes\",\n",
    "    \"total night calls\",\n",
    "    \"total night charge\",\n",
    "    \"total intl minutes\",\n",
    "    \"total intl calls\",\n",
    "    \"total intl charge\",\n",
    "    \"customer service calls\"\n",
    "]\n",
    "    \n",
    "    \n",
    "categorical_features = [\n",
    "    \"state\",\n",
    "    \"area code\",\n",
    "    \"international plan\", #bool\n",
    "    \"voice mail plan\" #bool\n",
    "]\n",
    "    \n",
    "drop_features = [\n",
    "    \"phone number\"\n",
    "]\n",
    "\n",
    "target = \"churn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\", drop='if_binary')\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_features),\n",
    "    (categorical_transformer, categorical_features),\n",
    "    (\"drop\", drop_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "* No imputation was needed as there was no missing data\n",
    "* Scaling was used to make sure the different units of measurement for all the different numeric features did not matter, and they could be compared on the same scale.\n",
    "* All the categorical features except for phone number (state, area code, international plan and voice mil plan) were transformed using one-hot encoding to convert the values into numeric columns so that a classifier can use them. Binary features were included here, with drop=if_binary so that one of the two columns created for binary features could be dropped. This helps reduce redundancy in the processed dataset.\n",
    "* Phone number was dropped as it was unique for every sample and unlikely to help with prediction. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 area code feature\n",
    "rubric={points:4}\n",
    "\n",
    "The original dataset had a feature called `area code`.\n",
    "\n",
    "1. The area codes are numbers. Does it make sense to encode them as one-hot-endoded (OHE) or not? Please justify your response.\n",
    "2. What were the possible values of `area code`? \n",
    "3. If area code is encoded with OHE, how many new features are created to replace it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "1. It makes sense to use OHE, as they should not be analysed for their numerical value but rather considered as separate categories.\n",
    "2. The values are '415', '408' and '510'.\n",
    "3. It will be converted into three new features, one for each value. If the original column is removed, there will be a total of two more columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Logistic regression\n",
    "rubric={points:12} \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Report the cross-validation results of a `LogisticRegression` model, with default Hparams, on the following metrics: `\"accuracy\", \"precision\", \"recall\", \"f1\"`\n",
    "2. Are you satisfied with the results? Explain why or why not. Discuss in a few sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.111260</td>\n",
       "      <td>0.030858</td>\n",
       "      <td>0.869379</td>\n",
       "      <td>0.371134</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.108423</td>\n",
       "      <td>0.017912</td>\n",
       "      <td>0.852248</td>\n",
       "      <td>0.273684</td>\n",
       "      <td>0.185714</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.093009</td>\n",
       "      <td>0.012869</td>\n",
       "      <td>0.850107</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.056610</td>\n",
       "      <td>0.014539</td>\n",
       "      <td>0.869099</td>\n",
       "      <td>0.371134</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.067795</td>\n",
       "      <td>0.016188</td>\n",
       "      <td>0.839056</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.413793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy   test_f1  test_recall  test_precision\n",
       "0  0.111260    0.030858       0.869379  0.371134     0.257143        0.666667\n",
       "1  0.108423    0.017912       0.852248  0.273684     0.185714        0.520000\n",
       "2  0.093009    0.012869       0.850107  0.255319     0.171429        0.500000\n",
       "3  0.056610    0.014539       0.869099  0.371134     0.260870        0.642857\n",
       "4  0.067795    0.016188       0.839056  0.242424     0.171429        0.413793"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code based on lecture 9\n",
    "scoring = [\"accuracy\", \"f1\", \"recall\", \"precision\"]\n",
    "pipe = make_pipeline(preprocessor, LogisticRegression())\n",
    "scores = cross_validate(pipe, X_train, y_train, scoring=scoring)\n",
    "#pd.DataFrame(scores).mean()\n",
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are not very satisfying, as while the accuracy score is high, the recall, precision and f1 scores are all very low. Recall is especially low, but if identifying those with churn=True is more important than churn=False, then recall may be more important than precision as false negatives may be worse than false positives. Thus these results are not good. \n",
    "\n",
    "These results may be due to the positive target class being much rarer than the negative class, leading to high accuracy (as the classifier correctly classifies most of the negative samples) but low precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Logistic regression with `class_weight`\n",
    "rubric={points:6}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Set the `class_weight` parameter of your logistic regression model to `'balanced'` and report the same metrics as in the previous part. \n",
    "2. Do you prefer this model to the one in the previous part? Discuss your results in a few sentences while comparing the metrics of this model and the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.073941</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.785867</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.071963</td>\n",
       "      <td>0.016082</td>\n",
       "      <td>0.768737</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.366197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085897</td>\n",
       "      <td>0.031168</td>\n",
       "      <td>0.764454</td>\n",
       "      <td>0.455446</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.348485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.126709</td>\n",
       "      <td>0.026434</td>\n",
       "      <td>0.751073</td>\n",
       "      <td>0.462963</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.340136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.134762</td>\n",
       "      <td>0.022076</td>\n",
       "      <td>0.733906</td>\n",
       "      <td>0.436364</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.320000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy   test_f1  test_recall  test_precision\n",
       "0  0.073941    0.016509       0.785867  0.489796     0.685714        0.380952\n",
       "1  0.071963    0.016082       0.768737  0.490566     0.742857        0.366197\n",
       "2  0.085897    0.031168       0.764454  0.455446     0.657143        0.348485\n",
       "3  0.126709    0.026434       0.751073  0.462963     0.724638        0.340136\n",
       "4  0.134762    0.022076       0.733906  0.436364     0.685714        0.320000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_balanced = make_pipeline(preprocessor, LogisticRegression(class_weight=\"balanced\"))\n",
    "scores_balanced = cross_validate(pipe_balanced, X_train, y_train, scoring=scoring)\n",
    "#pd.DataFrame(scores).mean()\n",
    "pd.DataFrame(scores_balanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison of the mean CV scores from logistic regression with unbalanced and balanced class weights:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_unbalanced</th>\n",
       "      <th>0_balanced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fit_time</th>\n",
       "      <td>0.087419</td>\n",
       "      <td>0.098654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_time</th>\n",
       "      <td>0.018473</td>\n",
       "      <td>0.022454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_accuracy</th>\n",
       "      <td>0.855978</td>\n",
       "      <td>0.760807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_f1</th>\n",
       "      <td>0.302739</td>\n",
       "      <td>0.467027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_recall</th>\n",
       "      <td>0.209317</td>\n",
       "      <td>0.699213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_precision</th>\n",
       "      <td>0.548663</td>\n",
       "      <td>0.351154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0_unbalanced  0_balanced\n",
       "fit_time            0.087419    0.098654\n",
       "score_time          0.018473    0.022454\n",
       "test_accuracy       0.855978    0.760807\n",
       "test_f1             0.302739    0.467027\n",
       "test_recall         0.209317    0.699213\n",
       "test_precision      0.548663    0.351154"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores1 = pd.DataFrame(scores).mean()\n",
    "scores2 = pd.DataFrame(scores_balanced).mean()\n",
    "scores1.to_frame().join(scores2.to_frame(), lsuffix=\"_unbalanced\", rsuffix=\"_balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy and precision dropped, but recall improved, as did the f1 score. Even though precision dropped, the f1 score improving shows that the improvement in recall was large enough that if precision and recall are equally important, then this model performs better than the previous one. \n",
    "\n",
    "Additionally, if the goal is to identify those with churn=True, recall is more important than precision and accuracy. As recall is much better here, this would be a more useful model for this goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Hyperparameter optimization\n",
    "rubric={points:10}\n",
    "\n",
    "1. Jointly optimize `C` and `class_weight` with `GridSearchCV` and `scoring=\"f1\"`.\n",
    "  - For `class_weight`, consider 3 values: \n",
    "    - `None` (no weight)\n",
    "    - \"weight of class 0 = 1\"  and  \"weight of class 1 = 3\"\n",
    "    - '`balanced`'\n",
    "  - For `C`, choose some reasonable values\n",
    "2. What values of `C` and `class_weight` are chosen and what is the best cross-validation f1 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code based on lecture 8\n",
    "param_grid = {\n",
    "    \"logisticregression__class_weight\":  [\"None\", {0:1, 1:3}, \"balanced\"],\n",
    "    \"logisticregression__C\": [0.001, 0.01, 0.1, 1.0, 10, 100],\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    pipe, param_grid, cv=5, n_jobs=-1, scoring=\"f1\", return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;standardscaler&#x27;,\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         [&#x27;account &#x27;\n",
       "                                                                          &#x27;length&#x27;,\n",
       "                                                                          &#x27;number &#x27;\n",
       "                                                                          &#x27;vmail &#x27;\n",
       "                                                                          &#x27;messages&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;day &#x27;\n",
       "                                                                          &#x27;minutes&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;day &#x27;\n",
       "                                                                          &#x27;calls&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;day &#x27;\n",
       "                                                                          &#x27;charge&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;eve &#x27;\n",
       "                                                                          &#x27;minutes&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;eve &#x27;\n",
       "                                                                          &#x27;calls&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;eve &#x27;\n",
       "                                                                          &#x27;charge&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;night &#x27;\n",
       "                                                                          &#x27;minutes&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;night &#x27;\n",
       "                                                                          &#x27;calls&#x27;,\n",
       "                                                                          &#x27;...\n",
       "                                                                                       handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                                         [&#x27;state&#x27;,\n",
       "                                                                          &#x27;area &#x27;\n",
       "                                                                          &#x27;code&#x27;,\n",
       "                                                                          &#x27;international &#x27;\n",
       "                                                                          &#x27;plan&#x27;,\n",
       "                                                                          &#x27;voice &#x27;\n",
       "                                                                          &#x27;mail &#x27;\n",
       "                                                                          &#x27;plan&#x27;]),\n",
       "                                                                        (&#x27;drop&#x27;,\n",
       "                                                                         &#x27;drop&#x27;,\n",
       "                                                                         [&#x27;phone &#x27;\n",
       "                                                                          &#x27;number&#x27;])])),\n",
       "                                       (&#x27;logisticregression&#x27;,\n",
       "                                        LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;logisticregression__C&#x27;: [0.001, 0.01, 0.1, 1.0, 10,\n",
       "                                                   100],\n",
       "                         &#x27;logisticregression__class_weight&#x27;: [&#x27;None&#x27;,\n",
       "                                                              {0: 1, 1: 3},\n",
       "                                                              &#x27;balanced&#x27;]},\n",
       "             return_train_score=True, scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;standardscaler&#x27;,\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         [&#x27;account &#x27;\n",
       "                                                                          &#x27;length&#x27;,\n",
       "                                                                          &#x27;number &#x27;\n",
       "                                                                          &#x27;vmail &#x27;\n",
       "                                                                          &#x27;messages&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;day &#x27;\n",
       "                                                                          &#x27;minutes&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;day &#x27;\n",
       "                                                                          &#x27;calls&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;day &#x27;\n",
       "                                                                          &#x27;charge&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;eve &#x27;\n",
       "                                                                          &#x27;minutes&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;eve &#x27;\n",
       "                                                                          &#x27;calls&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;eve &#x27;\n",
       "                                                                          &#x27;charge&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;night &#x27;\n",
       "                                                                          &#x27;minutes&#x27;,\n",
       "                                                                          &#x27;total &#x27;\n",
       "                                                                          &#x27;night &#x27;\n",
       "                                                                          &#x27;calls&#x27;,\n",
       "                                                                          &#x27;...\n",
       "                                                                                       handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                                         [&#x27;state&#x27;,\n",
       "                                                                          &#x27;area &#x27;\n",
       "                                                                          &#x27;code&#x27;,\n",
       "                                                                          &#x27;international &#x27;\n",
       "                                                                          &#x27;plan&#x27;,\n",
       "                                                                          &#x27;voice &#x27;\n",
       "                                                                          &#x27;mail &#x27;\n",
       "                                                                          &#x27;plan&#x27;]),\n",
       "                                                                        (&#x27;drop&#x27;,\n",
       "                                                                         &#x27;drop&#x27;,\n",
       "                                                                         [&#x27;phone &#x27;\n",
       "                                                                          &#x27;number&#x27;])])),\n",
       "                                       (&#x27;logisticregression&#x27;,\n",
       "                                        LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;logisticregression__C&#x27;: [0.001, 0.01, 0.1, 1.0, 10,\n",
       "                                                   100],\n",
       "                         &#x27;logisticregression__class_weight&#x27;: [&#x27;None&#x27;,\n",
       "                                                              {0: 1, 1: 3},\n",
       "                                                              &#x27;balanced&#x27;]},\n",
       "             return_train_score=True, scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler(),\n",
       "                                                  [&#x27;account length&#x27;,\n",
       "                                                   &#x27;number vmail messages&#x27;,\n",
       "                                                   &#x27;total day minutes&#x27;,\n",
       "                                                   &#x27;total day calls&#x27;,\n",
       "                                                   &#x27;total day charge&#x27;,\n",
       "                                                   &#x27;total eve minutes&#x27;,\n",
       "                                                   &#x27;total eve calls&#x27;,\n",
       "                                                   &#x27;total eve charge&#x27;,\n",
       "                                                   &#x27;total night minutes&#x27;,\n",
       "                                                   &#x27;total night calls&#x27;,\n",
       "                                                   &#x27;total night charge&#x27;,\n",
       "                                                   &#x27;total intl minutes&#x27;,\n",
       "                                                   &#x27;total intl calls&#x27;,\n",
       "                                                   &#x27;total intl charge&#x27;,\n",
       "                                                   &#x27;customer service calls&#x27;]),\n",
       "                                                 (&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;if_binary&#x27;,\n",
       "                                                                handle_unknown=&#x27;ignore&#x27;),\n",
       "                                                  [&#x27;state&#x27;, &#x27;area code&#x27;,\n",
       "                                                   &#x27;international plan&#x27;,\n",
       "                                                   &#x27;voice mail plan&#x27;]),\n",
       "                                                 (&#x27;drop&#x27;, &#x27;drop&#x27;,\n",
       "                                                  [&#x27;phone number&#x27;])])),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;standardscaler&#x27;, StandardScaler(),\n",
       "                                 [&#x27;account length&#x27;, &#x27;number vmail messages&#x27;,\n",
       "                                  &#x27;total day minutes&#x27;, &#x27;total day calls&#x27;,\n",
       "                                  &#x27;total day charge&#x27;, &#x27;total eve minutes&#x27;,\n",
       "                                  &#x27;total eve calls&#x27;, &#x27;total eve charge&#x27;,\n",
       "                                  &#x27;total night minutes&#x27;, &#x27;total night calls&#x27;,\n",
       "                                  &#x27;total night charge&#x27;, &#x27;total intl minutes&#x27;,\n",
       "                                  &#x27;total intl calls&#x27;, &#x27;total intl charge&#x27;,\n",
       "                                  &#x27;customer service calls&#x27;]),\n",
       "                                (&#x27;onehotencoder&#x27;,\n",
       "                                 OneHotEncoder(drop=&#x27;if_binary&#x27;,\n",
       "                                               handle_unknown=&#x27;ignore&#x27;),\n",
       "                                 [&#x27;state&#x27;, &#x27;area code&#x27;, &#x27;international plan&#x27;,\n",
       "                                  &#x27;voice mail plan&#x27;]),\n",
       "                                (&#x27;drop&#x27;, &#x27;drop&#x27;, [&#x27;phone number&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">standardscaler</label><div class=\"sk-toggleable__content\"><pre>[&#x27;account length&#x27;, &#x27;number vmail messages&#x27;, &#x27;total day minutes&#x27;, &#x27;total day calls&#x27;, &#x27;total day charge&#x27;, &#x27;total eve minutes&#x27;, &#x27;total eve calls&#x27;, &#x27;total eve charge&#x27;, &#x27;total night minutes&#x27;, &#x27;total night calls&#x27;, &#x27;total night charge&#x27;, &#x27;total intl minutes&#x27;, &#x27;total intl calls&#x27;, &#x27;total intl charge&#x27;, &#x27;customer service calls&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">onehotencoder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;state&#x27;, &#x27;area code&#x27;, &#x27;international plan&#x27;, &#x27;voice mail plan&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;if_binary&#x27;, handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop</label><div class=\"sk-toggleable__content\"><pre>[&#x27;phone number&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">drop</label><div class=\"sk-toggleable__content\"><pre>drop</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('columntransformer',\n",
       "                                        ColumnTransformer(transformers=[('standardscaler',\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         ['account '\n",
       "                                                                          'length',\n",
       "                                                                          'number '\n",
       "                                                                          'vmail '\n",
       "                                                                          'messages',\n",
       "                                                                          'total '\n",
       "                                                                          'day '\n",
       "                                                                          'minutes',\n",
       "                                                                          'total '\n",
       "                                                                          'day '\n",
       "                                                                          'calls',\n",
       "                                                                          'total '\n",
       "                                                                          'day '\n",
       "                                                                          'charge',\n",
       "                                                                          'total '\n",
       "                                                                          'eve '\n",
       "                                                                          'minutes',\n",
       "                                                                          'total '\n",
       "                                                                          'eve '\n",
       "                                                                          'calls',\n",
       "                                                                          'total '\n",
       "                                                                          'eve '\n",
       "                                                                          'charge',\n",
       "                                                                          'total '\n",
       "                                                                          'night '\n",
       "                                                                          'minutes',\n",
       "                                                                          'total '\n",
       "                                                                          'night '\n",
       "                                                                          'calls',\n",
       "                                                                          '...\n",
       "                                                                                       handle_unknown='ignore'),\n",
       "                                                                         ['state',\n",
       "                                                                          'area '\n",
       "                                                                          'code',\n",
       "                                                                          'international '\n",
       "                                                                          'plan',\n",
       "                                                                          'voice '\n",
       "                                                                          'mail '\n",
       "                                                                          'plan']),\n",
       "                                                                        ('drop',\n",
       "                                                                         'drop',\n",
       "                                                                         ['phone '\n",
       "                                                                          'number'])])),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'logisticregression__C': [0.001, 0.01, 0.1, 1.0, 10,\n",
       "                                                   100],\n",
       "                         'logisticregression__class_weight': ['None',\n",
       "                                                              {0: 1, 1: 3},\n",
       "                                                              'balanced']},\n",
       "             return_train_score=True, scoring='f1')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logisticregression__C': 0.1,\n",
       " 'logisticregression__class_weight': {0: 1, 1: 3}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4901064071511795"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer for 2:\n",
    "\n",
    "The value chosen for C is 0.1, and for class_weight is \"weight of class 0 = 1\" and \"weight of class 1 = 3\". The best cross-validation score, with scoring=\"f1\", is 0.49.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Test results\n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks**\n",
    "1. Evaluate the best model on the test set. In particular show each of the following on the test set:  \n",
    "    - Plot Confusion matrix\n",
    "    - Plot Precision-recall curve \n",
    "    - Calculate average precision score\n",
    "    - Plot ROC curve\n",
    "    - Report AUC score\n",
    "3. Comment on the AUC score and give an intuitive explanation of what this value of AUC means for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olsen L\\.conda\\envs\\cpsc330\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "C:\\Users\\Olsen L\\AppData\\Local\\Temp\\ipykernel_7180\\3928478250.py:15: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "#from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "pipe_best = make_pipeline(preprocessor, LogisticRegression(C=0.1, class_weight={0: 1, 1: 3}))\n",
    "pipe_best.fit(X_train, y_train)\n",
    "plot_confusion_matrix(\n",
    "    pipe_best,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    display_labels=[\"Not churn\", \"Churn\"],\n",
    "    values_format=\"d\",\n",
    "    cmap=plt.cm.Blues,\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PR curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code based on lecture 9\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(\n",
    "    y_test, pipe_best.predict_proba(X_test)[:, 1]\n",
    ")\n",
    "plt.plot(precision, recall, label=\"logistic regression: PR curve\")\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.plot(\n",
    "    precision_score(y_test, pipe_best.predict(X_test)),\n",
    "    recall_score(y_test, pipe_best.predict(X_test)),\n",
    "    \"or\",\n",
    "    markersize=10,\n",
    "    label=\"threshold 0.5\",\n",
    ")\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average precision score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average precision score: 0.465\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "ap_lr = average_precision_score(y_test, pipe_best.predict_proba(X_test)[:, 1])\n",
    "print(\"Average precision score: {:.3f}\".format(ap_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROC curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, pipe_best.predict_proba(X_test)[:, 1])\n",
    "plt.plot(fpr, tpr, label=\"ROC Curve\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR (recall)\")\n",
    "\n",
    "default_threshold = np.argmin(np.abs(thresholds - 0.5))\n",
    "\n",
    "plt.plot(\n",
    "    fpr[default_threshold],\n",
    "    tpr[default_threshold],\n",
    "    \"or\",\n",
    "    markersize=10,\n",
    "    label=\"threshold 0.5\",\n",
    ")\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AUC score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_lr = roc_auc_score(y_test, pipe_best.predict_proba(X_test)[:, 1])\n",
    "print(\"AUC: {:.3f}\".format(roc_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC is fairly high, which means that most positive examples are ranked higher by the model than most negative examples. This means that it is possible for the classifier to distinguish fairly well between the two closes, though the exact number of false positives and false negatives that will be present depends on the threshold chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Regression metrics <a name=\"3\"></a>\n",
    "<hr> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we'll use [California housing dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) from `sklearn datasets`. The code below loads the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing_df = fetch_california_housing(as_frame=True).frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: Data spitting and exploration \n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the data into train (75%) and test (25%) splits. \n",
    "2. Explore the train split. Do you need to apply any transformations on the data? If yes, create a preprocessor with the appropriate transformations. \n",
    "3. Separate `X` and `y` to train and test splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "calhousing_train_df, calhousing_test_df = train_test_split(housing_df, test_size=0.25, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>1.0349</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.165217</td>\n",
       "      <td>0.982609</td>\n",
       "      <td>734.0</td>\n",
       "      <td>3.191304</td>\n",
       "      <td>36.19</td>\n",
       "      <td>-119.35</td>\n",
       "      <td>0.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17889</th>\n",
       "      <td>4.7625</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.265207</td>\n",
       "      <td>1.002433</td>\n",
       "      <td>1087.0</td>\n",
       "      <td>2.644769</td>\n",
       "      <td>37.41</td>\n",
       "      <td>-121.95</td>\n",
       "      <td>1.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>3.5192</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.747475</td>\n",
       "      <td>1.845118</td>\n",
       "      <td>796.0</td>\n",
       "      <td>2.680135</td>\n",
       "      <td>38.61</td>\n",
       "      <td>-120.44</td>\n",
       "      <td>0.980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6861</th>\n",
       "      <td>2.8672</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.635616</td>\n",
       "      <td>1.090411</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>3.095890</td>\n",
       "      <td>34.06</td>\n",
       "      <td>-118.13</td>\n",
       "      <td>1.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11247</th>\n",
       "      <td>4.1276</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.429936</td>\n",
       "      <td>0.963376</td>\n",
       "      <td>1749.0</td>\n",
       "      <td>2.785032</td>\n",
       "      <td>33.81</td>\n",
       "      <td>-118.00</td>\n",
       "      <td>1.538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "19995  1.0349       6.0  4.165217   0.982609       734.0  3.191304     36.19   \n",
       "17889  4.7625      13.0  5.265207   1.002433      1087.0  2.644769     37.41   \n",
       "1977   3.5192       9.0  8.747475   1.845118       796.0  2.680135     38.61   \n",
       "6861   2.8672      30.0  4.635616   1.090411      1130.0  3.095890     34.06   \n",
       "11247  4.1276      13.0  4.429936   0.963376      1749.0  2.785032     33.81   \n",
       "\n",
       "       Longitude  MedHouseVal  \n",
       "19995    -119.35        0.678  \n",
       "17889    -121.95        1.375  \n",
       "1977     -120.44        0.980  \n",
       "6861     -118.13        1.985  \n",
       "11247    -118.00        1.538  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calhousing_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MedInc         0\n",
       "HouseAge       0\n",
       "AveRooms       0\n",
       "AveBedrms      0\n",
       "Population     0\n",
       "AveOccup       0\n",
       "Latitude       0\n",
       "Longitude      0\n",
       "MedHouseVal    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calhousing_train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No missing data, all numeric columns\n",
    "calhousing_preprocessor = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO check this is the right target column\n",
    "calhousing_X_train = calhousing_train_df.drop(columns=[\"MedHouseVal\"])\n",
    "calhousing_y_train = calhousing_train_df[\"MedHouseVal\"]\n",
    "\n",
    "calhousing_X_test = calhousing_test_df.drop(columns=[\"MedHouseVal\"])\n",
    "calhousing_y_test = calhousing_test_df[\"MedHouseVal\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Baseline: Linear Regression \n",
    "rubric={points:2}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Carry out cross-validation using `sklearn.linear_model.LinearRegression` with default scoring. \n",
    "2. What metric is used for scoring by default? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time       0.024461\n",
       "score_time     0.004417\n",
       "test_score     0.486547\n",
       "train_score    0.606753\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "calhousing_pipe = make_pipeline(calhousing_preprocessor, LinearRegression())\n",
    "calhousing_scores = cross_validate(calhousing_pipe, calhousing_X_train, calhousing_y_train, return_train_score=True)\n",
    "pd.DataFrame(calhousing_scores).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default scoring metric for sklearn cross validaton is accuracy. #TODO check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Random Forest Regressor\n",
    "rubric={points:7}\n",
    "\n",
    "In this exercise, we are going to use [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) model which we haven't looked into yet. At this point you should feel comfortable using models with our usual ML workflow even if you don't know the details. We'll talk about `RandomForestRegressor` later in the course.  \n",
    "\n",
    "The code below defines a custom scorer called `mape_scorer` and creates dictionaries for two model (`models`) and five evaluation metrics (`score_types_reg`). \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Using the `models` and the evaluation metrics `score_types_reg` in the code below, carry out cross-validation with each model, by passing the evaluation metrics to `scoring` argument of `cross_validate`. Use a pipeline with the model as an estimator if you are applying any transformations. \n",
    "2. Show results as a dataframe. \n",
    "3. Interpret the results. How do the models compare to the baseline? Which model seems to be performing well with different metrics? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "}\n",
    "\n",
    "score_types_reg = {\n",
    "    \"neg_mean_squared_error\": \"neg_mean_squared_error\",\n",
    "    \"neg_root_mean_squared_error\": \"neg_root_mean_squared_error\",\n",
    "    \"neg_mean_absolute_error\": \"neg_mean_absolute_error\",\n",
    "    \"r2\": \"r2\",\n",
    "    \"neg_mean_absolute_percentage_error\": \"neg_mean_absolute_percentage_error\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list=[]\n",
    "for k in models.keys():\n",
    "    for s in score_types_reg.keys():\n",
    "        columns_list.append(k+\"_\"+s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olsen L\\AppData\\Local\\Temp\\ipykernel_7180\\1981450243.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_scores = all_scores.append(pd.DataFrame(data={\n",
      "C:\\Users\\Olsen L\\AppData\\Local\\Temp\\ipykernel_7180\\1981450243.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_scores = all_scores.append(pd.DataFrame(data={\n",
      "C:\\Users\\Olsen L\\AppData\\Local\\Temp\\ipykernel_7180\\1981450243.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_scores = all_scores.append(pd.DataFrame(data={\n",
      "C:\\Users\\Olsen L\\AppData\\Local\\Temp\\ipykernel_7180\\1981450243.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_scores = all_scores.append(pd.DataFrame(data={\n",
      "C:\\Users\\Olsen L\\AppData\\Local\\Temp\\ipykernel_7180\\1981450243.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_scores = all_scores.append(pd.DataFrame(data={\n",
      "C:\\Users\\Olsen L\\AppData\\Local\\Temp\\ipykernel_7180\\1981450243.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_scores = all_scores.append(pd.DataFrame(data={\n",
      "C:\\Users\\Olsen L\\AppData\\Local\\Temp\\ipykernel_7180\\1981450243.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_scores = all_scores.append(pd.DataFrame(data={\n",
      "C:\\Users\\Olsen L\\AppData\\Local\\Temp\\ipykernel_7180\\1981450243.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_scores = all_scores.append(pd.DataFrame(data={\n",
      "C:\\Users\\Olsen L\\AppData\\Local\\Temp\\ipykernel_7180\\1981450243.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_scores = all_scores.append(pd.DataFrame(data={\n",
      "C:\\Users\\Olsen L\\AppData\\Local\\Temp\\ipykernel_7180\\1981450243.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_scores = all_scores.append(pd.DataFrame(data={\n"
     ]
    }
   ],
   "source": [
    "all_scores = pd.DataFrame(columns=[\"model\", \"score_types_reg\", \"fit_time\", \"score_time\", \"test_score\", \"train_score\"])\n",
    "\n",
    "for mkey in models:\n",
    "    for skey in score_types_reg:\n",
    "        new_pipe = make_pipeline(StandardScaler(), models.get(mkey))\n",
    "        new_scores = cross_validate(new_pipe, calhousing_X_train, calhousing_y_train,\n",
    "                                    scoring=score_types_reg.get(skey), \n",
    "                                    cv=5,\n",
    "                                    return_train_score=True,\n",
    "                                    n_jobs=-1)\n",
    "        new_mean_scores = pd.DataFrame(new_scores).mean()\n",
    "        all_scores = all_scores.append(pd.DataFrame(data={\n",
    "            \"model\":mkey,\n",
    "            \"score_types_reg\":skey,\n",
    "            \"fit_time\":new_mean_scores[0],\n",
    "            \"score_time\":new_mean_scores[1],\n",
    "            \"test_score\":new_mean_scores[2],\n",
    "            \"train_score\":new_mean_scores[3]}, index=[0]))\n",
    "        \n",
    "        #all_scores = all_scores.join(pd.DataFrame(new_scores).mean().to_frame(), rsuffix=(mkey+\"_\"+ skey))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_types_reg</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>0.043249</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>-0.678763</td>\n",
       "      <td>-0.525484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>0.023568</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>-0.808948</td>\n",
       "      <td>-0.724900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>0.012572</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>-0.536109</td>\n",
       "      <td>-0.531897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>r2</td>\n",
       "      <td>0.019115</td>\n",
       "      <td>0.005791</td>\n",
       "      <td>0.486522</td>\n",
       "      <td>0.606753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>neg_mean_absolute_percentage_error</td>\n",
       "      <td>0.019220</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>-0.319265</td>\n",
       "      <td>-0.316948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>19.178342</td>\n",
       "      <td>0.194319</td>\n",
       "      <td>-0.269841</td>\n",
       "      <td>-0.037825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>17.390696</td>\n",
       "      <td>0.180930</td>\n",
       "      <td>-0.517977</td>\n",
       "      <td>-0.193691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>17.536776</td>\n",
       "      <td>0.137911</td>\n",
       "      <td>-0.339298</td>\n",
       "      <td>-0.126158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>r2</td>\n",
       "      <td>18.689453</td>\n",
       "      <td>0.188790</td>\n",
       "      <td>0.800246</td>\n",
       "      <td>0.972004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>neg_mean_absolute_percentage_error</td>\n",
       "      <td>16.882446</td>\n",
       "      <td>0.147875</td>\n",
       "      <td>-0.191471</td>\n",
       "      <td>-0.071220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model                     score_types_reg   fit_time  score_time  \\\n",
       "0          Ridge              neg_mean_squared_error   0.043249    0.003397   \n",
       "0          Ridge         neg_root_mean_squared_error   0.023568    0.003590   \n",
       "0          Ridge             neg_mean_absolute_error   0.012572    0.003815   \n",
       "0          Ridge                                  r2   0.019115    0.005791   \n",
       "0          Ridge  neg_mean_absolute_percentage_error   0.019220    0.005784   \n",
       "0  Random Forest              neg_mean_squared_error  19.178342    0.194319   \n",
       "0  Random Forest         neg_root_mean_squared_error  17.390696    0.180930   \n",
       "0  Random Forest             neg_mean_absolute_error  17.536776    0.137911   \n",
       "0  Random Forest                                  r2  18.689453    0.188790   \n",
       "0  Random Forest  neg_mean_absolute_percentage_error  16.882446    0.147875   \n",
       "\n",
       "   test_score  train_score  \n",
       "0   -0.678763    -0.525484  \n",
       "0   -0.808948    -0.724900  \n",
       "0   -0.536109    -0.531897  \n",
       "0    0.486522     0.606753  \n",
       "0   -0.319265    -0.316948  \n",
       "0   -0.269841    -0.037825  \n",
       "0   -0.517977    -0.193691  \n",
       "0   -0.339298    -0.126158  \n",
       "0    0.800246     0.972004  \n",
       "0   -0.191471    -0.071220  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Olsen L\\AppData\\Local\\Temp\\ipykernel_7180\\3816019696.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  base_scores = base_scores.append(pd.DataFrame(data={\n",
      "C:\\Users\\Olsen L\\AppData\\Local\\Temp\\ipykernel_7180\\3816019696.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  base_scores = base_scores.append(pd.DataFrame(data={\n",
      "C:\\Users\\Olsen L\\AppData\\Local\\Temp\\ipykernel_7180\\3816019696.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  base_scores = base_scores.append(pd.DataFrame(data={\n",
      "C:\\Users\\Olsen L\\AppData\\Local\\Temp\\ipykernel_7180\\3816019696.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  base_scores = base_scores.append(pd.DataFrame(data={\n",
      "C:\\Users\\Olsen L\\AppData\\Local\\Temp\\ipykernel_7180\\3816019696.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  base_scores = base_scores.append(pd.DataFrame(data={\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_types_reg</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear regression (baseline)</td>\n",
       "      <td>neg_mean_squared_error</td>\n",
       "      <td>0.024355</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>-0.678732</td>\n",
       "      <td>-0.525484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear regression (baseline)</td>\n",
       "      <td>neg_root_mean_squared_error</td>\n",
       "      <td>0.029524</td>\n",
       "      <td>0.005766</td>\n",
       "      <td>-0.808935</td>\n",
       "      <td>-0.724900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear regression (baseline)</td>\n",
       "      <td>neg_mean_absolute_error</td>\n",
       "      <td>0.022271</td>\n",
       "      <td>0.005845</td>\n",
       "      <td>-0.536112</td>\n",
       "      <td>-0.531901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear regression (baseline)</td>\n",
       "      <td>r2</td>\n",
       "      <td>0.023967</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>0.486547</td>\n",
       "      <td>0.606753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear regression (baseline)</td>\n",
       "      <td>neg_mean_absolute_percentage_error</td>\n",
       "      <td>0.027471</td>\n",
       "      <td>0.005507</td>\n",
       "      <td>-0.319275</td>\n",
       "      <td>-0.316957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model                     score_types_reg  fit_time  \\\n",
       "0  Linear regression (baseline)              neg_mean_squared_error  0.024355   \n",
       "0  Linear regression (baseline)         neg_root_mean_squared_error  0.029524   \n",
       "0  Linear regression (baseline)             neg_mean_absolute_error  0.022271   \n",
       "0  Linear regression (baseline)                                  r2  0.023967   \n",
       "0  Linear regression (baseline)  neg_mean_absolute_percentage_error  0.027471   \n",
       "\n",
       "   score_time  test_score  train_score  \n",
       "0    0.004327   -0.678732    -0.525484  \n",
       "0    0.005766   -0.808935    -0.724900  \n",
       "0    0.005845   -0.536112    -0.531901  \n",
       "0    0.004866    0.486547     0.606753  \n",
       "0    0.005507   -0.319275    -0.316957  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_scores = pd.DataFrame(columns=[\"model\", \"score_types_reg\", \"fit_time\", \"score_time\", \"test_score\", \"train_score\"])\n",
    "for skey in score_types_reg:\n",
    "    new_pipe = make_pipeline(StandardScaler(),LinearRegression())\n",
    "    new_scores = cross_validate(new_pipe, calhousing_X_train, calhousing_y_train,\n",
    "                                scoring=score_types_reg.get(skey), \n",
    "                                cv=5,\n",
    "                                return_train_score=True,\n",
    "                                n_jobs=-1)\n",
    "    new_mean_scores = pd.DataFrame(new_scores).mean()\n",
    "    base_scores = base_scores.append(pd.DataFrame(data={\n",
    "        \"model\":\"Linear regression (baseline)\",\n",
    "        \"score_types_reg\":skey,\n",
    "        \"fit_time\":new_mean_scores[0],\n",
    "        \"score_time\":new_mean_scores[1],\n",
    "        \"test_score\":new_mean_scores[2],\n",
    "        \"train_score\":new_mean_scores[3]}, index=[0]))\n",
    "    \n",
    "base_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Interpret the results. How do the models compare to the baseline? Which model seems to be performing well with different metrics?*\n",
    "Random forest does better in all the metrics. It is hard to compare to the baseline score from part 3.2 as the only score found there is accuracy, which is not very relevant to regression and also not found for the models above. \n",
    "If the above metrics are computed for the baseline model, it appears that it performs similar to Ridge and not as well as Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Hyperparameter optimization \n",
    "rubric={points:1}\n",
    "\n",
    "1. Carry out hyperparameter optimization using `RandomizedSearchCV` and `Ridge` with the following `param_dist`. The `alpha` hyperparameter of `Ridge` controls the fundamental tradeoff. Choose `neg_mean_absolute_percentage_error` as the HParam optimization metric.\n",
    "\n",
    "2. What was the best `alpha` hyper-parameter found?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import loguniform\n",
    "\n",
    "param_dist = {\"ridge__alpha\": loguniform(1e-3, 1e3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code based on lecture 8\n",
    "ridge_pipe = make_pipeline(StandardScaler(), Ridge())\n",
    "random_search = RandomizedSearchCV(\n",
    "    ridge_pipe, param_dist, cv=5, n_jobs=-1, \n",
    "    scoring=\"neg_mean_absolute_percentage_error\", return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                              StandardScaler()),\n",
       "                                             (&#x27;ridge&#x27;, Ridge())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;ridge__alpha&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001D51C3BE9E0&gt;},\n",
       "                   return_train_score=True,\n",
       "                   scoring=&#x27;neg_mean_absolute_percentage_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;standardscaler&#x27;,\n",
       "                                              StandardScaler()),\n",
       "                                             (&#x27;ridge&#x27;, Ridge())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={&#x27;ridge__alpha&#x27;: &lt;scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001D51C3BE9E0&gt;},\n",
       "                   return_train_score=True,\n",
       "                   scoring=&#x27;neg_mean_absolute_percentage_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()), (&#x27;ridge&#x27;, Ridge())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('standardscaler',\n",
       "                                              StandardScaler()),\n",
       "                                             ('ridge', Ridge())]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'ridge__alpha': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x000001D51C3BE9E0>},\n",
       "                   return_train_score=True,\n",
       "                   scoring='neg_mean_absolute_percentage_error')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(calhousing_X_train, calhousing_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha value found: 6.5845627760815\n"
     ]
    }
   ],
   "source": [
    "print(\"Best alpha value found:\", random_search.best_params_['ridge__alpha'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Test results\n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Test the best model (from 3.4) on the test set based on the `neg_mean_absolute_percentage_error` score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.31629894778149004"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.score(calhousing_X_test, calhousing_y_test)\n",
    "#TODO so bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Model interpretation  \n",
    "rubric={points:4}\n",
    "\n",
    "Ridge is a linear model and it learns coefficients associated with each feature during `fit()`. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Explore coefficients learned by the `Ridge` model above as a pandas dataframe with two columns: \n",
    "   - features \n",
    "   - coefficients\n",
    "2. Increasing which feature values would result in higher housing price? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_coefs = pd.DataFrame(columns = [\"features\", \"coefficients\"])\n",
    "ridge_coefs[\"features\"] = calhousing_X_train.columns\n",
    "ridge_coefs[\"coefficients\"] = random_search.best_estimator_['ridge'].coef_\n",
    "#TODO check if there is better way to get column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MedInc</td>\n",
       "      <td>0.832961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HouseAge</td>\n",
       "      <td>0.121884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AveRooms</td>\n",
       "      <td>-0.265999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AveBedrms</td>\n",
       "      <td>0.300797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Population</td>\n",
       "      <td>-0.001746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AveOccup</td>\n",
       "      <td>-0.042208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Latitude</td>\n",
       "      <td>-0.855737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Longitude</td>\n",
       "      <td>-0.824917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     features  coefficients\n",
       "0      MedInc      0.832961\n",
       "1    HouseAge      0.121884\n",
       "2    AveRooms     -0.265999\n",
       "3   AveBedrms      0.300797\n",
       "4  Population     -0.001746\n",
       "5    AveOccup     -0.042208\n",
       "6    Latitude     -0.855737\n",
       "7   Longitude     -0.824917"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing MedInc or HousAge would result in higher housing prices, as they have positive coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Submission instructions \n",
    "\n",
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from “1” will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using Gradescope's drag and drop tool. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:.conda-cpsc330]",
   "language": "python",
   "name": "conda-env-.conda-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "name": "_merged",
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "438px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
