{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 3: Preprocessing \n",
    "### Associated lectures: [Lectures 4, 5, 6](https://ubc-cs.github.io/cpsc330/README.html) \n",
    "\n",
    "**Due date: Wednesday, Feb 01, 2023 at 11:59pm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [Instructions](#si)\n",
    "- [Introduction](#in)\n",
    "- [Exercise 1: Introducing the dataset](#1)\n",
    "- [Exercise 2: Exploratory data analysis (EDA)](#2)\n",
    "- [Exercise 3: Preprocessing](#3)\n",
    "- [Exercise 4: Building models](#4)\n",
    "- [Exercise 5: Evaluating on the test set](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions <a name=\"si\"></a>\n",
    "<hr>\n",
    "rubric={points:6}\n",
    "\n",
    "Follow the [homework submission instructions](https://github.com/UBC-CS/cpsc330-2022W2/blob/main/docs/homework_instructions.md). \n",
    "\n",
    "**You may work with a partner on this homework (maximum group size: 2).** \n",
    "\n",
    "_Note: The assignments will get gradually more open-ended as we progress through the course. In many cases, there won't be a single correct solution. Sometimes you will have to make your own choices and your own decisions (for example, on what parameter values to use when they are not explicitly provided in the instructions). Use your own judgment in such cases and justify your choices, if necessary._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3247a4b883a670c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Introduction <a name=\"in\"></a>\n",
    "<hr>\n",
    "\n",
    "A crucial step when using machine learning algorithms on real-world datasets is preprocessing. This homework will give you some practice of data preprocessing and building a supervised machine learning pipeline on a real-world dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Introducing the dataset <a name=\"1\"></a>\n",
    "<hr>\n",
    "\n",
    "In this lab, you will be working on [the adult census dataset](https://www.kaggle.com/uciml/adult-census-income#). Download the CSV and save it as `adult.csv` locally in this homework folder. \n",
    "\n",
    "This is a classification dataset and the classification task is to predict whether income exceeds 50K per year or not based on the census data. You can find more information on the dataset and features [here](http://archive.ics.uci.edu/ml/datasets/Adult).\n",
    "\n",
    "The starter code below loads the data CSV (assuming that it is saved as `adult.csv` in this folder). \n",
    "\n",
    "_Note that many popular datasets have sex as a feature where the possible values are male and female. This representation reflects how the data were collected and is not meant to imply that, for example, gender is binary._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_df = pd.read_csv(\"./adult.csv\")\n",
    "census_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data splitting \n",
    "rubric={points:4}\n",
    "\n",
    "In order to avoid violation of the golden rule, the first step before we do anything is splitting the data. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Split the data into `train_df` (60%) and `test_df` (40%) with `random_state = 42`. Keep the target column (`income`) in the splits so that we can use it in the exploratory data analysis.  \n",
    "\n",
    "_Usually having more data for training is a good idea. But here we're using a 60%/40% split because this is kind of a big dataset for a modest laptop. A smaller training set means that it won't take too long to train the model on your laptop. A side advantage of this would be that with a bigger test split, we'll have a more reliable estimate of the deployment performance!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(census_df, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 2: Exploratory data analysis (EDA) <a name=\"2\"></a> \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine our `train_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>?</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>216864</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3770</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>70037</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>3004</td>\n",
       "      <td>60</td>\n",
       "      <td>?</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32553</th>\n",
       "      <td>43</td>\n",
       "      <td>Private</td>\n",
       "      <td>84661</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32554</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>116138</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32555</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>321865</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19536 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass  fnlwgt     education  education.num      marital.status  \\\n",
       "0       90         ?   77053       HS-grad              9             Widowed   \n",
       "1       82   Private  132870       HS-grad              9             Widowed   \n",
       "2       66         ?  186061  Some-college             10             Widowed   \n",
       "5       34   Private  216864       HS-grad              9            Divorced   \n",
       "9       41   Private   70037  Some-college             10       Never-married   \n",
       "...    ...       ...     ...           ...            ...                 ...   \n",
       "32553   43   Private   84661     Assoc-voc             11  Married-civ-spouse   \n",
       "32554   32   Private  116138       Masters             14       Never-married   \n",
       "32555   53   Private  321865       Masters             14  Married-civ-spouse   \n",
       "32557   27   Private  257302    Assoc-acdm             12  Married-civ-spouse   \n",
       "32559   58   Private  151910       HS-grad              9             Widowed   \n",
       "\n",
       "            occupation   relationship                race     sex  \\\n",
       "0                    ?  Not-in-family               White  Female   \n",
       "1      Exec-managerial  Not-in-family               White  Female   \n",
       "2                    ?      Unmarried               Black  Female   \n",
       "5        Other-service      Unmarried               White  Female   \n",
       "9         Craft-repair      Unmarried               White    Male   \n",
       "...                ...            ...                 ...     ...   \n",
       "32553            Sales        Husband               White    Male   \n",
       "32554     Tech-support  Not-in-family  Asian-Pac-Islander    Male   \n",
       "32555  Exec-managerial        Husband               White    Male   \n",
       "32557     Tech-support           Wife               White  Female   \n",
       "32559     Adm-clerical      Unmarried               White  Female   \n",
       "\n",
       "       capital.gain  capital.loss  hours.per.week native.country income  \n",
       "0                 0          4356              40  United-States  <=50K  \n",
       "1                 0          4356              18  United-States  <=50K  \n",
       "2                 0          4356              40  United-States  <=50K  \n",
       "5                 0          3770              45  United-States  <=50K  \n",
       "9                 0          3004              60              ?   >50K  \n",
       "...             ...           ...             ...            ...    ...  \n",
       "32553             0             0              45  United-States  <=50K  \n",
       "32554             0             0              11         Taiwan  <=50K  \n",
       "32555             0             0              40  United-States   >50K  \n",
       "32557             0             0              38  United-States  <=50K  \n",
       "32559             0             0              40  United-States  <=50K  \n",
       "\n",
       "[19536 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see some missing values represented with a \"?\". Probably these were the questions not answered by some people during the census.  Usually `.describe()` or `.info()` methods would give you information on missing values. But here, they won't pick \"?\" as missing values as they are encoded as strings instead of an actual NaN in Python. So let's replace them with `np.nan` before we carry out EDA. If you do not do it, you'll encounter an error later on when you try to pass this data to a classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19536, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_nan = train_df.replace(\"?\", np.nan)\n",
    "test_df_nan = test_df.replace(\"?\", np.nan)\n",
    "train_df_nan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>216864</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3770</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>70037</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>3004</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32553</th>\n",
       "      <td>43</td>\n",
       "      <td>Private</td>\n",
       "      <td>84661</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32554</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>116138</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32555</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>321865</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19536 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age workclass  fnlwgt     education  education.num      marital.status  \\\n",
       "0       90       NaN   77053       HS-grad              9             Widowed   \n",
       "1       82   Private  132870       HS-grad              9             Widowed   \n",
       "2       66       NaN  186061  Some-college             10             Widowed   \n",
       "5       34   Private  216864       HS-grad              9            Divorced   \n",
       "9       41   Private   70037  Some-college             10       Never-married   \n",
       "...    ...       ...     ...           ...            ...                 ...   \n",
       "32553   43   Private   84661     Assoc-voc             11  Married-civ-spouse   \n",
       "32554   32   Private  116138       Masters             14       Never-married   \n",
       "32555   53   Private  321865       Masters             14  Married-civ-spouse   \n",
       "32557   27   Private  257302    Assoc-acdm             12  Married-civ-spouse   \n",
       "32559   58   Private  151910       HS-grad              9             Widowed   \n",
       "\n",
       "            occupation   relationship                race     sex  \\\n",
       "0                  NaN  Not-in-family               White  Female   \n",
       "1      Exec-managerial  Not-in-family               White  Female   \n",
       "2                  NaN      Unmarried               Black  Female   \n",
       "5        Other-service      Unmarried               White  Female   \n",
       "9         Craft-repair      Unmarried               White    Male   \n",
       "...                ...            ...                 ...     ...   \n",
       "32553            Sales        Husband               White    Male   \n",
       "32554     Tech-support  Not-in-family  Asian-Pac-Islander    Male   \n",
       "32555  Exec-managerial        Husband               White    Male   \n",
       "32557     Tech-support           Wife               White  Female   \n",
       "32559     Adm-clerical      Unmarried               White  Female   \n",
       "\n",
       "       capital.gain  capital.loss  hours.per.week native.country income  \n",
       "0                 0          4356              40  United-States  <=50K  \n",
       "1                 0          4356              18  United-States  <=50K  \n",
       "2                 0          4356              40  United-States  <=50K  \n",
       "5                 0          3770              45  United-States  <=50K  \n",
       "9                 0          3004              60            NaN   >50K  \n",
       "...             ...           ...             ...            ...    ...  \n",
       "32553             0             0              45  United-States  <=50K  \n",
       "32554             0             0              11         Taiwan  <=50K  \n",
       "32555             0             0              40  United-States   >50K  \n",
       "32557             0             0              38  United-States  <=50K  \n",
       "32559             0             0              40  United-States  <=50K  \n",
       "\n",
       "[19536 rows x 15 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_nan.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"?\" symbols are now replaced with NaN values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Visualizing features\n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Examine the information given by `train_df_nan.info()` and `train_df_nan.describe()` methods. In case of `.describe()`, use the `include=\"all\"` argument to show summary statistics of all  features.\n",
    "2. Visualize the histograms of numeric features. \n",
    "3. From the visualizations, which features seem relevant for the given prediction task?\n",
    "\n",
    "> Note: (Optional) If you're feeling excited about this you are welcome to use [`pandas_profiling`](https://github.com/pandas-profiling/pandas-profiling) for more elaborate visualization and EDA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19536 entries, 25823 to 23654\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             19536 non-null  int64 \n",
      " 1   workclass       18428 non-null  object\n",
      " 2   fnlwgt          19536 non-null  int64 \n",
      " 3   education       19536 non-null  object\n",
      " 4   education.num   19536 non-null  int64 \n",
      " 5   marital.status  19536 non-null  object\n",
      " 6   occupation      18424 non-null  object\n",
      " 7   relationship    19536 non-null  object\n",
      " 8   race            19536 non-null  object\n",
      " 9   sex             19536 non-null  object\n",
      " 10  capital.gain    19536 non-null  int64 \n",
      " 11  capital.loss    19536 non-null  int64 \n",
      " 12  hours.per.week  19536 non-null  int64 \n",
      " 13  native.country  19187 non-null  object\n",
      " 14  income          19536 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df_nan.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19536.000000</td>\n",
       "      <td>18428</td>\n",
       "      <td>1.953600e+04</td>\n",
       "      <td>19536</td>\n",
       "      <td>19536.000000</td>\n",
       "      <td>19536</td>\n",
       "      <td>18424</td>\n",
       "      <td>19536</td>\n",
       "      <td>19536</td>\n",
       "      <td>19536</td>\n",
       "      <td>19536.000000</td>\n",
       "      <td>19536.000000</td>\n",
       "      <td>19536.000000</td>\n",
       "      <td>19187</td>\n",
       "      <td>19536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Private</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>13570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9025</td>\n",
       "      <td>2490</td>\n",
       "      <td>7937</td>\n",
       "      <td>16676</td>\n",
       "      <td>13079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17517</td>\n",
       "      <td>14841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.592547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.892662e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.084767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1090.443540</td>\n",
       "      <td>86.537162</td>\n",
       "      <td>40.532606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.638971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.049020e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.580723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7449.700833</td>\n",
       "      <td>402.395668</td>\n",
       "      <td>12.406636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.228500e+04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.177670e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.782835e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.368860e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.455435e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age workclass        fnlwgt education  education.num  \\\n",
       "count   19536.000000     18428  1.953600e+04     19536   19536.000000   \n",
       "unique           NaN         8           NaN        16            NaN   \n",
       "top              NaN   Private           NaN   HS-grad            NaN   \n",
       "freq             NaN     13570           NaN      6256            NaN   \n",
       "mean       38.592547       NaN  1.892662e+05       NaN      10.084767   \n",
       "std        13.638971       NaN  1.049020e+05       NaN       2.580723   \n",
       "min        17.000000       NaN  1.228500e+04       NaN       1.000000   \n",
       "25%        28.000000       NaN  1.177670e+05       NaN       9.000000   \n",
       "50%        37.000000       NaN  1.782835e+05       NaN      10.000000   \n",
       "75%        47.000000       NaN  2.368860e+05       NaN      12.000000   \n",
       "max        90.000000       NaN  1.455435e+06       NaN      16.000000   \n",
       "\n",
       "            marital.status      occupation relationship   race    sex  \\\n",
       "count                19536           18424        19536  19536  19536   \n",
       "unique                   7              14            6      5      2   \n",
       "top     Married-civ-spouse  Prof-specialty      Husband  White   Male   \n",
       "freq                  9025            2490         7937  16676  13079   \n",
       "mean                   NaN             NaN          NaN    NaN    NaN   \n",
       "std                    NaN             NaN          NaN    NaN    NaN   \n",
       "min                    NaN             NaN          NaN    NaN    NaN   \n",
       "25%                    NaN             NaN          NaN    NaN    NaN   \n",
       "50%                    NaN             NaN          NaN    NaN    NaN   \n",
       "75%                    NaN             NaN          NaN    NaN    NaN   \n",
       "max                    NaN             NaN          NaN    NaN    NaN   \n",
       "\n",
       "        capital.gain  capital.loss  hours.per.week native.country income  \n",
       "count   19536.000000  19536.000000    19536.000000          19187  19536  \n",
       "unique           NaN           NaN             NaN             41      2  \n",
       "top              NaN           NaN             NaN  United-States  <=50K  \n",
       "freq             NaN           NaN             NaN          17517  14841  \n",
       "mean     1090.443540     86.537162       40.532606            NaN    NaN  \n",
       "std      7449.700833    402.395668       12.406636            NaN    NaN  \n",
       "min         0.000000      0.000000        1.000000            NaN    NaN  \n",
       "25%         0.000000      0.000000       40.000000            NaN    NaN  \n",
       "50%         0.000000      0.000000       40.000000            NaN    NaN  \n",
       "75%         0.000000      0.000000       45.000000            NaN    NaN  \n",
       "max     99999.000000   4356.000000       99.000000            NaN    NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_nan.describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x274f4170a60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#getting numeric columns and separating by class\n",
    "numeric_train_df = train_df.loc[:,((train_df.dtypes== 'int64').values | (train_df.columns == 'income'))]\n",
    "under_50k_dat = numeric_train_df[numeric_train_df.income == '<=50K']\n",
    "over_50k_dat = numeric_train_df[numeric_train_df.income == '>50K']\n",
    "\n",
    "#plotting histograms for each numeric column\n",
    "fig, axis = plt.subplots(2,3,figsize=(6, 6))\n",
    "under_50k_dat.hist(ax=axis, label = \"under 50k\")\n",
    "over_50k_dat.hist(ax=axis, label = \"over 50k\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*From the visualizations, which features seem relevant for the given prediction task?*\n",
    "\n",
    "Answer: 'age', 'education.num', and 'capital.gain' seem more relevant than others for the given prediction task, as their distributions for each class is somewhat different. While there is overlap in the ditributions, especially in age, there is enough of a difference that e.g. probability of classification into <=50k would likely be higher for someone below 25."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Identify transformations to apply\n",
    "rubric={points:18}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Identify the sequence of transformations that you would apply on each column in the dataset and fill in the table below accordingly. An example of the sequence of transformations to be applied on the `occupation` feature is shown in the table below. You may decide not to apply any transformations on a certain column or entirely drop a column from your model. That's totally fine. \n",
    "2. Are there common transformations you would like to apply on certain types of features? Identify different feature types for applying different transformations. In particular, fill in the lists below. \n",
    "3. Is including the `race` feature for predicting income ethically a good idea? Briefly discuss. \n",
    "\n",
    "> Note: This question is a bit open-ended and there is no single correct solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature | Transformation |\n",
    "| --- | ----------- |\n",
    "| occupation | imputation, OHE |\n",
    "| age | scaling |\n",
    "| workclass | imputation, OHE |\n",
    "| fnlwgt | (none) |\n",
    "| education | (none) |\n",
    "| education.num | scaling |\n",
    "| marital.status | OHE |\n",
    "| relationship | OHE |\n",
    "| race | OHE |\n",
    "| sex | OHE |\n",
    "| capital.gain | scaling |\n",
    "| capital.loss | scaling |\n",
    "| hours.per.week | scaling |\n",
    "| native.country | imputation, OHE |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the lists below. \n",
    "# It's OK to keep some of the lists empty or add new lists. \n",
    "numeric_features = ['age', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']\n",
    "categorical_features = ['workclass', 'marital.status', 'occupation', 'relationship', 'race', 'native.country']\n",
    "ordinal_features = []\n",
    "binary_features = ['sex']\n",
    "drop_features = ['fnlwgt','education']\n",
    "passthrough_features = []\n",
    "target = \"income\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Are there common transformations you would like to apply on certain types of features? Identify different feature types for applying different transformations.*\n",
    "Answer: \n",
    "- Imputation can be carried out on all the features, to save time from picking out the ones that have missing values. \n",
    "- Scaling needs to be carried out on all the numeric features\n",
    "- OHE needs to be carried out on all the categorical features\n",
    "- OHE can be carried out on binary features, or a similar encoding where only one of the columns is kept (e.g. sex -> male = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Is including the `race` feature for predicting income ethically a good idea? Briefly discuss.*\n",
    "\n",
    "It depends on the context it will be used in. For example, if race is a strong predictor of income but is excluded, and the classifier is being used for something such as giving financial aid to those predicted to have income below the cutoff, some people who need aid may not receive it. However, if the classifier is used for some task where those with a certain income would be negatively affected, e.g. only allowing those with a high income to have a membership to a club, then including race may lead to certain people getting unfair advantages or disadvantages.\n",
    "\n",
    "Overall, however, including race could lead to unfair stereotyping and is generally not ethically a good idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Separating feature vectors and targets  \n",
    "rubric={points:4}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create `X_train`, `y_train`, `X_test`, `y_test` from `train_df_nan` and `test_df_nan`. \n",
    "2. At this point, if you train [`sklearn`'s `SVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) model on `X_train` and `y_train` would it work? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df_nan.drop(columns = ['income'])\n",
    "y_train = train_df_nan[\"income\"]\n",
    "X_test = test_df_nan.drop(columns = ['income'])\n",
    "y_test = test_df_nan[\"income\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "*At this point, if you train [`sklearn`'s `SVC`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) model on `X_train` and `y_train` would it work? Why or why not?*\n",
    "\n",
    "No, it doesn't work. After the fit, SVC will be calculating the distances between the input vector and the support vectors in order to make its prediction. But with the categorical features, there is no logic upon determining the distances between different categories of that feature. Thus, it rejects to train on the current data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Preprocessing <a name=\"3\"></a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Preprocessing using `sklearn`'s `ColumnTransformer` and `Pipeline`\n",
    "rubric={points:18}\n",
    "\n",
    "Let's carry out preprocessing using `sklearn`'s `ColumnTransformer` and `Pipeline`. Note that you can define pipelines in two ways: \n",
    "- by using [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) and explicitly providing named steps\n",
    "- by using [`make_pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html#sklearn.pipeline.make_pipeline), which automatically names the steps in the pipeline with their class names. \n",
    "\n",
    "Similarly you can create a column transformer in two ways:\n",
    "- by using [`ColumnTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html)\n",
    "- by using [`make_column_transformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html) \n",
    "\n",
    "You may use the method of your choice but `make_pipeline` and `make_column_transformer` are highly recommended.  \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create a column transformer `preprocessor` based on transformations you want to apply on the data from 2.2. \n",
    "2. Transform the data by calling `fit_transform` on the training set. What's the shape of the transformed data? \n",
    "3. Why do we need to use a column transformer in this case? Briefly explain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code based on lecture 6\n",
    "\n",
    "#note: countries and other cat. variables still in dataset;\n",
    "#optionally could transform them by grouping or some other method so the processed data\n",
    "#isn't so sparse\n",
    "\n",
    "numeric_tranformer = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler())\n",
    "cat_transformer = make_pipeline(SimpleImputer(strategy=\"most_frequent\"),  \n",
    "                                    OneHotEncoder(handle_unknown=\"ignore\",  \n",
    "                                                  sparse= False))\n",
    "bin_transformer = make_pipeline(SimpleImputer(strategy=\"most_frequent\"),  \n",
    "                                    OneHotEncoder(handle_unknown=\"ignore\", \n",
    "                                                  drop='if_binary', \n",
    "                                                  sparse= False))\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_tranformer, numeric_features),\n",
    "    (cat_transformer, categorical_features),\n",
    "    (bin_transformer, binary_features),\n",
    "    ('drop', drop_features),\n",
    "    ('passthrough', passthrough_features)    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prep = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19536, 87)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_prep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformed data has many more columns than before due to the one-hot encoding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Why do we need to use a column transformer in this case? Briefly explain.*\n",
    "\n",
    "In preparing of training the data set under the model other a decision tree, categorical data need to be transforming into numerical data;\n",
    "scaling need to be enforce on numerical features to avoid domination; converting certain categorical data into binary data to decrease the number of feature.\n",
    "As you can see, there are multiple transformation that need to make of the current X data set, to adhere to the DRY (Don't Repeat Yourself) principle, a pipeline would be useful to conclude all the transformations needed.\n",
    "And the last but not the least, in case of applying cross validation, pipeline is needed to apply  need to take to avoid breaking \n",
    "the golden rule between the training set and the verification set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exercise 4: Building models <a name=\"4\"></a>\n",
    "<hr>\n",
    "\n",
    "Now that we have preprocessed features, we are ready to build models. Below is the function we used in class, which returns the mean cross-validation score along with standard deviation for a given model. Feel free to use it to keep track of your results if you like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "results_dict = {} # dictionary to store all the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.1 Baseline model \n",
    "rubric={points:6}\n",
    "\n",
    "**Your tasks:**\n",
    "1. Define a pipeline with two steps: `preprocessor` from 3.1 and `scikit-learn`'s `DummyClassifier` with `strategy=\"prior\"` as your classifier.  \n",
    "2. Carry out 5-fold cross-validation with the pipeline. Store the results in `results_dict` above. Display the results as a pandas DataFrame.  \n",
    "\n",
    "> You may use the function `mean_std_cross_val_scores` above to carry out cross-validation and storing results. Refer to the class notes if you are unsure about how to use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dummy</th>\n",
       "      <td>0.056 (+/- 0.001)</td>\n",
       "      <td>0.019 (+/- 0.004)</td>\n",
       "      <td>0.760 (+/- 0.000)</td>\n",
       "      <td>0.760 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                fit_time         score_time         test_score  \\\n",
       "dummy  0.056 (+/- 0.001)  0.019 (+/- 0.004)  0.760 (+/- 0.000)   \n",
       "\n",
       "             train_score  \n",
       "dummy  0.760 (+/- 0.000)  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_pipe = make_pipeline(preprocessor, DummyClassifier(strategy = \"prior\"))\n",
    "\n",
    "results_dict[\"dummy\"] = mean_std_cross_val_scores(\n",
    "    classifier_pipe, X_train, y_train, cv=5, return_train_score = True\n",
    ")\n",
    "pd.DataFrame(results_dict).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.2 Trying different classifiers\n",
    "rubric={points:14}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. For each of the models in the starter code below: \n",
    "    - Define a pipeline with two steps: `preprocessor` from 3.1 and the model as your classifier. \n",
    "    - Carry out 5-fold cross-validation with the pipeline.  \n",
    "    - Store the results in `results_dict`. \n",
    "2. Display all the results so far as a pandas dataframe. \n",
    "3. Compare the train and validation accuracies and `fit` and `score` times in each case. How do the the validation accuracies compare to the baseline model from 4.1? Which model has the best validation accuracy? Which model is the fastest one?  \n",
    "\n",
    "> Note that this might take a while to run.\n",
    "\n",
    "> You may use the function above `mean_std_cross_val_scores` to carry out cross-validation and storing results. Refer to the class notes if you are unsure about how to use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"decision tree\": DecisionTreeClassifier(),\n",
    "    \"kNN\": KNeighborsClassifier(),\n",
    "    \"RBF SVM\": SVC(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in models:\n",
    "    pipe = make_pipeline(preprocessor, models[key])\n",
    "    results_dict[key] = mean_std_cross_val_scores(\n",
    "    pipe, X_train, y_train, cv=5, return_train_score = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dummy</th>\n",
       "      <td>0.056 (+/- 0.001)</td>\n",
       "      <td>0.019 (+/- 0.004)</td>\n",
       "      <td>0.760 (+/- 0.000)</td>\n",
       "      <td>0.760 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>0.162 (+/- 0.002)</td>\n",
       "      <td>0.019 (+/- 0.001)</td>\n",
       "      <td>0.815 (+/- 0.004)</td>\n",
       "      <td>0.983 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kNN</th>\n",
       "      <td>0.062 (+/- 0.002)</td>\n",
       "      <td>0.340 (+/- 0.061)</td>\n",
       "      <td>0.835 (+/- 0.005)</td>\n",
       "      <td>0.883 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBF SVM</th>\n",
       "      <td>9.242 (+/- 0.773)</td>\n",
       "      <td>2.836 (+/- 0.089)</td>\n",
       "      <td>0.854 (+/- 0.005)</td>\n",
       "      <td>0.866 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        fit_time         score_time         test_score  \\\n",
       "dummy          0.056 (+/- 0.001)  0.019 (+/- 0.004)  0.760 (+/- 0.000)   \n",
       "decision tree  0.162 (+/- 0.002)  0.019 (+/- 0.001)  0.815 (+/- 0.004)   \n",
       "kNN            0.062 (+/- 0.002)  0.340 (+/- 0.061)  0.835 (+/- 0.005)   \n",
       "RBF SVM        9.242 (+/- 0.773)  2.836 (+/- 0.089)  0.854 (+/- 0.005)   \n",
       "\n",
       "                     train_score  \n",
       "dummy          0.760 (+/- 0.000)  \n",
       "decision tree  0.983 (+/- 0.001)  \n",
       "kNN            0.883 (+/- 0.001)  \n",
       "RBF SVM        0.866 (+/- 0.002)  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Compare the train and validation accuracies and `fit` and `score` times in each case. How do the the validation accuracies compare to the baseline model from 4.1? Which model has the best validation accuracy? Which model is the fastest one?*\n",
    "\n",
    "The validation scores of these models all have increased compared to the baseline model. RBF SVM has the best validation accuracy and decision tree is the fastest one to be trained and to make the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) 4.3 Exploring the importance of scaling\n",
    "rubric={points:1}\n",
    "\n",
    "In this exercise you'll examine whether scaling helps in case of KNNs and SVM RBFs. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Create a column transformer without the `StandardScaler` step for `numeric_features`. \n",
    "2. Repeat the steps in 4.2 with this new column transformer. \n",
    "3. Compare the results of scaled numeric features with unscaled numeric features. Is scaling necessary for decision trees? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_tranformer = make_pipeline(SimpleImputer(strategy=\"median\"))\n",
    "cat_transformer = make_pipeline(SimpleImputer(strategy=\"most_frequent\"),  \n",
    "                                    OneHotEncoder(handle_unknown=\"ignore\",  \n",
    "                                                  sparse= False))\n",
    "bin_transformer = make_pipeline(SimpleImputer(strategy=\"most_frequent\"),  \n",
    "                                    OneHotEncoder(handle_unknown=\"ignore\", \n",
    "                                                  drop='if_binary', \n",
    "                                                  sparse= False))\n",
    "\n",
    "preprocessor_4_3 = make_column_transformer(\n",
    "    (numeric_tranformer, numeric_features),\n",
    "    (cat_transformer, categorical_features),\n",
    "    (bin_transformer, binary_features),\n",
    "    ('drop', drop_features),\n",
    "    ('passthrough', passthrough_features)    \n",
    ")\n",
    "\n",
    "for key in models:\n",
    "    pipe = make_pipeline(preprocessor_4_3, models[key])\n",
    "    results_dict[key+\"_4_3\"] = mean_std_cross_val_scores(\n",
    "    pipe, X_train, y_train, cv=5, return_train_score = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dummy</th>\n",
       "      <td>0.056 (+/- 0.001)</td>\n",
       "      <td>0.019 (+/- 0.004)</td>\n",
       "      <td>0.760 (+/- 0.000)</td>\n",
       "      <td>0.760 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>0.162 (+/- 0.002)</td>\n",
       "      <td>0.019 (+/- 0.001)</td>\n",
       "      <td>0.815 (+/- 0.004)</td>\n",
       "      <td>0.983 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kNN</th>\n",
       "      <td>0.062 (+/- 0.002)</td>\n",
       "      <td>0.340 (+/- 0.061)</td>\n",
       "      <td>0.835 (+/- 0.005)</td>\n",
       "      <td>0.883 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBF SVM</th>\n",
       "      <td>9.242 (+/- 0.773)</td>\n",
       "      <td>2.836 (+/- 0.089)</td>\n",
       "      <td>0.854 (+/- 0.005)</td>\n",
       "      <td>0.866 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree_4_3</th>\n",
       "      <td>0.187 (+/- 0.008)</td>\n",
       "      <td>0.021 (+/- 0.000)</td>\n",
       "      <td>0.816 (+/- 0.006)</td>\n",
       "      <td>0.983 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kNN_4_3</th>\n",
       "      <td>0.076 (+/- 0.003)</td>\n",
       "      <td>0.376 (+/- 0.016)</td>\n",
       "      <td>0.843 (+/- 0.004)</td>\n",
       "      <td>0.891 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBF SVM_4_3</th>\n",
       "      <td>9.771 (+/- 0.159)</td>\n",
       "      <td>3.366 (+/- 0.055)</td>\n",
       "      <td>0.803 (+/- 0.004)</td>\n",
       "      <td>0.803 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            fit_time         score_time         test_score  \\\n",
       "dummy              0.056 (+/- 0.001)  0.019 (+/- 0.004)  0.760 (+/- 0.000)   \n",
       "decision tree      0.162 (+/- 0.002)  0.019 (+/- 0.001)  0.815 (+/- 0.004)   \n",
       "kNN                0.062 (+/- 0.002)  0.340 (+/- 0.061)  0.835 (+/- 0.005)   \n",
       "RBF SVM            9.242 (+/- 0.773)  2.836 (+/- 0.089)  0.854 (+/- 0.005)   \n",
       "decision tree_4_3  0.187 (+/- 0.008)  0.021 (+/- 0.000)  0.816 (+/- 0.006)   \n",
       "kNN_4_3            0.076 (+/- 0.003)  0.376 (+/- 0.016)  0.843 (+/- 0.004)   \n",
       "RBF SVM_4_3        9.771 (+/- 0.159)  3.366 (+/- 0.055)  0.803 (+/- 0.004)   \n",
       "\n",
       "                         train_score  \n",
       "dummy              0.760 (+/- 0.000)  \n",
       "decision tree      0.983 (+/- 0.001)  \n",
       "kNN                0.883 (+/- 0.001)  \n",
       "RBF SVM            0.866 (+/- 0.002)  \n",
       "decision tree_4_3  0.983 (+/- 0.001)  \n",
       "kNN_4_3            0.891 (+/- 0.001)  \n",
       "RBF SVM_4_3        0.803 (+/- 0.001)  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not necessary for decision tree by comparing the test_score. Decision tree makes its prediction based on the threshold and it can only make one assumption of one feature at each split. The range of other features would interfere or dominate the other, hence, scaling is not necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Hyperparameter optimization\n",
    "rubric={points:10}\n",
    "\n",
    "In this exercise, you'll carry out hyperparameter optimization for the hyperparameter `C` of SVC RBF classifier. In practice you'll carry out hyperparameter optimization for all different hyperparameters for the most promising classifiers. For the purpose of this assignment, we'll only do it for the `SVC` classifier with one hyperparameter: `C`. \n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. For each `C` value in the `param_grid` in the starter code below: \n",
    "    - Create a pipeline object with two steps: preprocessor from 3.1 and `SVC` classifier with the value of `C`.\n",
    "    - Carry out 5-fold cross validation with the pipeline.  \n",
    "    - Store the results in `results_dict` and display results as a pandas DataFrame. \n",
    "2. Which hyperparameter value seems to be performing the best, and why? Is it different than the default value for the hyperparameter used by `scikit-learn`? \n",
    "\n",
    "> Note: Running this might take a while. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_vals = np.logspace(-2, 2, num=5, base=10)\n",
    "param_grid = {\"C\": np.delete(param_vals, np.where(param_vals == 1.0))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in param_grid[\"C\"]:\n",
    "    pipe_svc = make_pipeline(preprocessor, SVC(C = c))\n",
    "    results_dict[\"SVM C=\" + str(c)] = mean_std_cross_val_scores(\n",
    "    pipe_svc, X_train, y_train, cv=5, return_train_score = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dummy</th>\n",
       "      <td>0.056 (+/- 0.001)</td>\n",
       "      <td>0.019 (+/- 0.004)</td>\n",
       "      <td>0.760 (+/- 0.000)</td>\n",
       "      <td>0.760 (+/- 0.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree</th>\n",
       "      <td>0.162 (+/- 0.002)</td>\n",
       "      <td>0.019 (+/- 0.001)</td>\n",
       "      <td>0.815 (+/- 0.004)</td>\n",
       "      <td>0.983 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kNN</th>\n",
       "      <td>0.062 (+/- 0.002)</td>\n",
       "      <td>0.340 (+/- 0.061)</td>\n",
       "      <td>0.835 (+/- 0.005)</td>\n",
       "      <td>0.883 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBF SVM</th>\n",
       "      <td>9.242 (+/- 0.773)</td>\n",
       "      <td>2.836 (+/- 0.089)</td>\n",
       "      <td>0.854 (+/- 0.005)</td>\n",
       "      <td>0.866 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision tree_4_3</th>\n",
       "      <td>0.187 (+/- 0.008)</td>\n",
       "      <td>0.021 (+/- 0.000)</td>\n",
       "      <td>0.816 (+/- 0.006)</td>\n",
       "      <td>0.983 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kNN_4_3</th>\n",
       "      <td>0.076 (+/- 0.003)</td>\n",
       "      <td>0.376 (+/- 0.016)</td>\n",
       "      <td>0.843 (+/- 0.004)</td>\n",
       "      <td>0.891 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RBF SVM_4_3</th>\n",
       "      <td>9.771 (+/- 0.159)</td>\n",
       "      <td>3.366 (+/- 0.055)</td>\n",
       "      <td>0.803 (+/- 0.004)</td>\n",
       "      <td>0.803 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM C=0.01</th>\n",
       "      <td>11.817 (+/- 0.531)</td>\n",
       "      <td>4.082 (+/- 0.159)</td>\n",
       "      <td>0.826 (+/- 0.004)</td>\n",
       "      <td>0.827 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM C=0.1</th>\n",
       "      <td>10.336 (+/- 0.919)</td>\n",
       "      <td>3.378 (+/- 0.270)</td>\n",
       "      <td>0.852 (+/- 0.006)</td>\n",
       "      <td>0.854 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM C=10.0</th>\n",
       "      <td>11.828 (+/- 0.377)</td>\n",
       "      <td>3.029 (+/- 0.086)</td>\n",
       "      <td>0.853 (+/- 0.005)</td>\n",
       "      <td>0.885 (+/- 0.002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM C=100.0</th>\n",
       "      <td>21.497 (+/- 1.017)</td>\n",
       "      <td>3.031 (+/- 0.126)</td>\n",
       "      <td>0.844 (+/- 0.005)</td>\n",
       "      <td>0.905 (+/- 0.001)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             fit_time         score_time         test_score  \\\n",
       "dummy               0.056 (+/- 0.001)  0.019 (+/- 0.004)  0.760 (+/- 0.000)   \n",
       "decision tree       0.162 (+/- 0.002)  0.019 (+/- 0.001)  0.815 (+/- 0.004)   \n",
       "kNN                 0.062 (+/- 0.002)  0.340 (+/- 0.061)  0.835 (+/- 0.005)   \n",
       "RBF SVM             9.242 (+/- 0.773)  2.836 (+/- 0.089)  0.854 (+/- 0.005)   \n",
       "decision tree_4_3   0.187 (+/- 0.008)  0.021 (+/- 0.000)  0.816 (+/- 0.006)   \n",
       "kNN_4_3             0.076 (+/- 0.003)  0.376 (+/- 0.016)  0.843 (+/- 0.004)   \n",
       "RBF SVM_4_3         9.771 (+/- 0.159)  3.366 (+/- 0.055)  0.803 (+/- 0.004)   \n",
       "SVM C=0.01         11.817 (+/- 0.531)  4.082 (+/- 0.159)  0.826 (+/- 0.004)   \n",
       "SVM C=0.1          10.336 (+/- 0.919)  3.378 (+/- 0.270)  0.852 (+/- 0.006)   \n",
       "SVM C=10.0         11.828 (+/- 0.377)  3.029 (+/- 0.086)  0.853 (+/- 0.005)   \n",
       "SVM C=100.0        21.497 (+/- 1.017)  3.031 (+/- 0.126)  0.844 (+/- 0.005)   \n",
       "\n",
       "                         train_score  \n",
       "dummy              0.760 (+/- 0.000)  \n",
       "decision tree      0.983 (+/- 0.001)  \n",
       "kNN                0.883 (+/- 0.001)  \n",
       "RBF SVM            0.866 (+/- 0.002)  \n",
       "decision tree_4_3  0.983 (+/- 0.001)  \n",
       "kNN_4_3            0.891 (+/- 0.001)  \n",
       "RBF SVM_4_3        0.803 (+/- 0.001)  \n",
       "SVM C=0.01         0.827 (+/- 0.002)  \n",
       "SVM C=0.1          0.854 (+/- 0.001)  \n",
       "SVM C=10.0         0.885 (+/- 0.002)  \n",
       "SVM C=100.0        0.905 (+/- 0.001)  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results_dict).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Which hyperparameter value seems to be performing the best, and why? Is it different than the default value for the hyperparameter used by `scikit-learn`?*\n",
    "\n",
    "C=10.0 performed the best out of the given options. And there is no sign of overfitting since the gap between training and the test score is not big and the training score is not as high as 1. The value C decides the margin between the hyperplane and the points of the target classes. Thus, by selecting an relavent small one(compares to c=100), it avoids taking account of the outliers.\n",
    "The default value for C is 1.0, so this is different from the default. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Exercise 5: Evaluating on the test set <a name=\"5\"></a>\n",
    "<hr>\n",
    "\n",
    "Now that we have a best performing model, it's time to assess our model on the set aside test set. In this exercise you'll examine whether the results you obtained using cross-validation on the train set are consistent with the results on the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Scoring on the unseen test set \n",
    "rubric={points:10}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Train the best performing model on the entire training set. \n",
    "2. Report the results of this model on `X_test`. \n",
    "3. Are the cross-validation results and test results consistent? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit(X_train)\n",
    "X_train_imp = preprocessor.transform(X_train)\n",
    "X_test_imp = preprocessor.transform(X_test)\n",
    "svc = SVC(C=10)\n",
    "svc.fit(X_train_imp, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.855\n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy: %0.3f\" % (svc.score(X_test_imp, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Are the cross-validation results and test results consistent?*\n",
    "\n",
    "The test score is very close to the cross-validation score for SVC(), so the results are consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Summary\n",
    "\n",
    "rubric={Pass/Fail}\n",
    "\n",
    "You are all done with Homework 3! Your last task is reflecting on what you have learned and answering the following questions. **This task is necessary to pass HW3**. Failing to complete this task means you will not receive points for this assignment.\n",
    "\n",
    "1. In about 100 words, describe what you have learned from this homework.\n",
    "2. Write at least one well-formulated question on something that is still not clear about the content of this homework, or you would like to know more about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We had learned how to explore the data set by print the relevant data type of a large data set, this will help us to decide on the pre-processing processor. Furthermore, we had learned how to visualize the data by looking at the histogram of individual feature. By comparing the result between each model, we learnt how to consider the different features within a model that would help us to pick the best model and right pre-processor for that data set. We also learned the importance and the motivation to use a pre-processor and a pipeline, how they will benefit the model fitting process. It also inspired us to think about the ethical issues around the data set.\n",
    "\n",
    "2. What are some real life situations where we consider the time efficiency over accuracy, especially when we have a large data set?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions \n",
    "\n",
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`. \n",
    "2. Notebooks with cell execution numbers out of order or not starting from “1” will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Upload the assignment using Gradescope's drag and drop tool. Check out this [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/) if you need help with Gradescope submission. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a tricky one but I hope you are feeling good after working on it. You are now ready to build a simple supervised machine learning pipeline on real-world datasets! Well done (**and don't forget to submit**)! \n",
    "\n",
    "![](./eva-well-done.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python [conda env:.conda-cpsc330]",
   "language": "python",
   "name": "conda-env-.conda-cpsc330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
